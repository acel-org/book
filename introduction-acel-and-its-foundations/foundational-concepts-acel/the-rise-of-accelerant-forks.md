# The Rise of Accelerant Forks

## AI & the Rise in Popularity of Accelerationism

While kettling Accelerationism-proper into a cohesive framework proves a challenge, less so is locating the root catalyst of its recent rise in popularity, which can be backdropped against the sudden ubiquitous accessibility of AI technology; and with it, the existential paranoia with which it now seems to haunt modern society.

Only in just the last few years, our consumer markets have been flooded with a mass and an extension -- both unprecedented in scale -- of usable technological innovations. Most notable of these came in November 2022 with the debut of ChatGPT. With this tool, instantly, the once-esoteric, almost mystical technology known as artificial intelligence availed its utility to virtually everyone in the world, all at no cost ([Roose](https://www.nytimes.com/2022/12/05/technology/chatgpt-ai-twitter.html)). ChaptGPT ushered in a new paradigm of consumer-technology intimacy that day, where _anyone_ with a device and internet access could engage with AI technology ([Nielsen](https://www.nngroup.com/articles/ai-paradigm/)). And yet, humanity's response to this new locus of potentia came as a paralysis -- not of _joy_ in light of an unprecedented advancement, but of _existential_ _dread_ that it might kill us all one day.&#x20;

We as a species did not handle this fear with poise. Instead, we speculated -- in government hearings and courtrooms ([West](https://www.brookings.edu/articles/senate-hearing-highlights-ai-harms-and-need-for-tougher-regulation/); [Senate](https://oversight.house.gov/release/hearing-wrap-up-federal-government-use-of-artificial-intelligence-poses-promise-peril/); [Senate 2](https://oversight.house.gov/release/mace-announces-second-hearing-on-white-house-executive-order-on-ai%EF%BF%BC%EF%BF%BC/)) -- on the potential dangers of this new AI technology and the threats it posed, not just to our societal infrastructure and modern systems, but to our very _existence_: this flight-to-doom catalyzed a flight-to-policy, one so elephantine that it earned the moniker: AI Safetyism ([Brodsky](https://www.lifewire.com/even-the-creator-of-chatgpt-finds-ai-scary-but-not-everyone-agrees-7113525)). In the name of "caution" and "human safety", this agenda, backed by a critical mass of the tech's industry's most influential figures, pushed to centralize and bureaucratize (i.e. to slow) progress within the AI technological industry ([McMillan](https://www.wsj.com/tech/ai/openai-blowup-effective-altruism-disaster-f46a55e8)).&#x20;

One group in particular -- a niche, Silicon Valley-tied social movement by the name of "Effective Altruism" (EA) -- served as perhaps AI Safetyism's most formidable set of advocates ([Effective Altruism](https://www.effectivealtruism.org/)). Claiming a human-forward, quasi-utilitarian worldview where humans should pursue a life that actionably minimizes the suffering of humans, EA supports AI regulation on the basis that, without strict guidelines, development in the this industry would precipitate a higher likelihood of bringing about a "technological singularity": a phenomenon with devastating consequences for humankind. For these influential adherents of Effective Altruism, slowing the progress of AI development would be the safest, and therefore, most optimal route for our species.&#x20;

By and large, their success in these aims spawned from a flood of noncritical public image campaigns that the media painted of these ultra-rich-EA tech gurus -- these "ethical elite" -- who were marketed to the general public as more or less billionaire-saviors ([McGoey](https://jacobin.com/2023/01/effective-altruism-longtermism-nick-bostrom-racism)). Even non-target demographics, heretofore uninterested in legislative policy, took up EA's pro-government leanings: their advocacy for UBI and globalization, even their proposed forced redistribution of wealth -- brainwashed by a media  ([Berlatsky](https://www.everythingishorrible.net/p/effective-altruism-is-neither-effective)).

And yet, as rapidly as Effective Altruism became the hero in the public eye did it fall from grace, effecting such a disorientation that a counter movement arose, one that opposed the ideals of Accelerationism. Two very public events are sufficient here to explain the rise in popularity of _e/acc_, or, "Effective Accelerationism", a self-proclaimed "anti-EA" movement first started by formerly-anonymous X user [@BasedBeffJezos](https://twitter.com/BasedBeffJezos), whom we now know to be theoretical physicist Guillaume Verdon ([Friedman](https://podcasts.apple.com/au/podcast/lex-fridman-podcast/id1434243584?i=1000640047523)).&#x20;

First, in November of 2023, Sam Altman, CEO of OpenAI and creator of ChatGPT, was unexpectedly ousted from his position by the company's board of directors ([Tarantola](https://www.engadget.com/openai-ceo-sam-altman-ousted-as-board-no-longer-has-confidence-in-his-leadership-204924006.html)). While being fired is not uproarious in and of itself, that a number of self-proclaimed adherents of Effective Altruism had begun to fill OpenAI board seats and eventually took a majority, the media viewed this  "infiltration" as a coordinated, politically-motivated "takedown" by the EA movement, as Altman's removal would open EA to much greater agency in building the regulatory framework AI industry ([Broughel](https://www.forbes.com/sites/jamesbroughel/2023/11/20/effective-altruism-contributed-to-the-fiasco-at-openai/)).

The second event that sparked the rise of e/acc is the fall from grace of Sam Bankman-Fried (SBF), founder and former CEO of derivatives crypto exchange FTX ([Reiff](https://www.investopedia.com/what-went-wrong-with-ftx-6828447)). Undoubtedly once the highest profile adherent of Effective Altruism, SBF was, in no hyperbolic sense, regarded as a prophet, a visionary, a modern day savior who was going to save the world ([Lang](https://www.reuters.com/technology/sam-bankman-frieds-sudden-turn-white-knight-washout-2022-11-12/)).

Then, he was caught defrauding $8billion from his own customers, and he now sits the next 25 years in a prison cell ([Godoy, Cohen](https://www.reuters.com/technology/sam-bankman-fried-be-sentenced-multi-billion-dollar-ftx-fraud-2024-03-28/)). &#x20;

The public disillusionment with the once-infallible, "ethics-forward" frontmen of AI Safetyism incited a wave of influential reactionary opinions on regulation in AI. For example, Elon Musk, who, for a brief time took the stance of an AI Safety "Doomer" ([Twitter](https://x.com/elonmusk/status/896166762361704450)), turned about-face and made his AI software, Grok, open source, meaning that the public was free to use it themselves ([Knight](https://www.reuters.com/technology/sam-bankman-fried-be-sentenced-multi-billion-dollar-ftx-fraud-2024-03-28/)). This move was championed by pro-AI, anti-EA groups. One such group, e/acc, or "Effective Accelerationism", has garnered a good deal of public attention in light of its admittedly edgy stances and recommendations within the AI technology discourse.&#x20;

## ACCEL as e/acc Fork&#x20;

e/acc, whose name parodies EA, is indeed a self-proclaimed counter-movement "virus" intended to, according to its founder Guillaume Verdon, "bring a\[n] \[entropic] balance to the forces \[of constraint]" levied by Effective Altruism. It maintains clearly stated goals built for civilization; to measure success, e/acc -- like EA -- employs a certain "loss function" (i.e. in machine learning, a formulaic mapping of some non-quantifiable variable onto discrete numbers in order to portray a "cost" of said variable). While EA deploys "hedons", or units of hedonism, as its variable, e/acc uses energy ([Friedman](https://podcasts.apple.com/au/podcast/lex-fridman-podcast/id1434243584?i=1000640047523)).&#x20;

This is because e/acc's theoretical goal, as it is based in thermodynamics, is to increase entropy _at all cost_. On the ground, this physics-based pursuit primarily takes the form of advocating for unregulated AI development. It also interests itself in space exploration, pro-population and pro-economic policies -- all of these combine to the overall goal of e/acc, which is to maximize the amount of energy humans can harness, and for this it recommends nuclear fission as its optimal path forward ([Friedman](https://podcasts.apple.com/au/podcast/lex-fridman-podcast/id1434243584?i=1000640047523)).&#x20;

As we can see, with a thematic focus on output maximization, e/acc is Accelerationism bar none. Unfortunately, as it was born from a reactionary framework (against Effective Altruism), Effective Accelerationism seems to carry with it an off-putting and exclusionary spirit of aggression and technocapitalism. While playful, the self-identification as a _virus_ adds to an inherent desire to keep one's distance from it ([Friedman](https://podcasts.apple.com/au/podcast/lex-fridman-podcast/id1434243584?i=1000640047523)).  This leaves unscalable much of its potential promise.&#x20;

Enter ACEL: With a more inclusionary, human-centric framework of priority "outputs", thereby offering a friendlier and more palatable nature than "technocapitalism-or-bust", ACEL seeks to scale the potentialities latent in e/acc and bring them to a wider audience. While maintaining _energy_ as its loss function's core unit, by grounding its core beliefs in Mises's free market, and particularizing an interstellar researched plan, ACEL undeniably ties itself to e/acc; yet by reorienting its Accelerationist  output priorities to human intelligence, human agency, and human evolution, it thereby eases buy-in and palatability.&#x20;

\
