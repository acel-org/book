# Who Should Rule?

**Future Governance System: Who Should Rule?**

\
As we stand at the threshold of a new age—one defined by technology, rather than ideology—we're called upon to address a basic, almost philosophical question: Who shall rule? Thus far, governance structures were built on needs and limitations stemming from human society—nation, tribe, empire, democracy—all anchored in the biological and psychological make-up of humankind (Harari, 2017). But as the very definition of "intelligence" and "agency" starts to transcend our biological bounds, there is a need for governance to evolve beyond simple human hierarchies (Tegmark, 2017).

This gives Francis Fukuyama's famous assertion—that "the end of history" would be marked not by heroic ideological struggles but by an era of bureaucratic governance, economic calculation, and consumer satisfaction—an ominous echo in our time (Fukuyama, 1992).

It is humanity's great ideological wars—the revolutions, the wars of independence, the political philosophies seeking to define how people could best live together—that in large parts of the world have settled down into the banality of problem-solving, addressing environmental crises, and fulfilling the insatiable desires of a consumerist society (Hobsbawm, 1994). In that respect, Fukuyama did suggest it would be the ultimate tragedy: a world without struggle, ambition, and vision, replaced by banality.

But in a world rapidly accelerating towards a future in which intelligentsia may no longer be defined by human minds but by silicon, and later on by energy machines, who is to decide? Are we to leave this to the same structures of governance that defined the 20th century, or must we rethink what it means to lead, to rule, and to govern (Russell & Norvig, 2010)?

**The Death of Traditional Governance?**\
Governance has always been a manifestation of power: from the king's divine authority to the most modern democracies touting the people's will, governance has traditionally revolved around human beings dictating the lives of other human beings (Plato, 2000). But what happens when intelligence ceases to be the sole domain of humankind? What happens when the most formidable minds do not consist of flesh but of silicon, and later, energy itself (Bostrom, 2014)?

Traditional governance structures of our culture, based upon laws created by biological organisms, might no longer be adequate to deal with a world populated or dominated by artificial intelligence and its iterations yet to come (Floridi, 2014). Such machines, without human biases, biological needs, or passage of time, can make decisions in theory far more rationally and effectively than any institution created by humans (Brynjolfsson & McAfee, 2014).

Where silicon-energy machines have turned out to be superior, in almost all domains of intellectual activity, should we go on believing in the superiority of human-led governments (Bostrom, 2014)?

But, this new power brings fear—t**he Fear of the Unknown**. Giving machines the power to govern raises deep anxieties. Can a machine ever understand what a human being needs, wants, and feels? Will government by AI create a cold, calculating dystopia devoid of the milk of human kindness, or take us to a utopia of equity and fairness, a world free of corruption and inefficiencies that have burdened human governments since the time Adam first scratched sticks in the dirt (Damasio, 1999)?

**The Rise of Post-Human Governance**\
The very idea of governance by non-human intelligence questions some basic premises on which human civilization has been based: Man has always thought that governance—if nothing else—must essentially be men governing men. But does it have to? Has a world where machines are outpacing human cognition—making decisions based on big data and modeling complex outcomes of societies better than any political scientist—made the very notion of human-led governance a form of absurdity (Tegmark, 2017)?

We already see glimpses of this future in the developing usage of algorithms to make choices involving human lives in everything from finance and criminal justice to healthcare (O’Neil, 2016). These algorithms, though simple versus the AI of tomorrow, are early warning signs that machines can and will do more on governance. The shift from human governance toward that of post-human might be an inevitability, but only if the machines prove capable of information processing and decision-making on scales unimaginable by the human brain (Russell & Norvig, 2010).

And with the rise of machines comes a rise in questions about their legitimacy (Floridi, 2014).

Man, by nature, is an emotional animal. Human beings demand recognition, need empathy, and crave to be understood (Nussbaum, 2001). Can a machine, no matter how sophisticated, ever truly "rule" in a manner that would appease these deep-seated humanness-craving needs for equity, justice, and meaning?

To this effect, there is an increasing need to look towards a new breed of symbiosis between humans and machines in which governance is neither fully human-driven nor fully machine-driven, but collaborative, where machines help guide human decision-making on one end, and humans bring into governance the emotional and ethical considerations that machines would lack (Wiener, 1988).

**The Rebirth of a Philosopher-King**\
What may be required is that the governance mechanism of the future must derive its inspiration not from the bureaucratic traditions of either democracy or technocracy but from something more akin to the concept of the philosopher-king developed by Plato. In _The Republic_, Plato controversially argued that the ideal ruler was neither a warrior nor a politician but a philosopher—a man who had achieved the very highest level of understanding of justice and truth (Plato, 2000).

Might it be that our philosopher-kings, at some future date, are machines—creatures of pure intellect, unencumbered by the prejudices and fallibilities that have traditionally bedeviled rulers of human flesh and blood (Floridi, 2013)? These AI philosopher-kings would differ from their human forebears in their ability to process vast amounts of data, learn from all of human history, and model possible futures with unprecedented accuracy (Moravec, 1988). They could thus, in theory, make decisions not based on short-term gains or emotional predispositions but rather on the long-term flourishing of human civilization and the universe itself (Kurzweil, 2005).

But perhaps one thing remains constant, which is whether a machine, even an AI philosopher-king, could ever truly understand the human experience well enough to govern. Or will there always be an element to human governance that requires the human touch—a recognition of the emotional, irrational, and often contradictory nature of human beings (Damasio, 1999)?

**The Role of Human Wisdom**\
Human wisdom definitely cannot be ruled out by intelligent machines. For all the advances of silicon-and-energy machines, there is something uniquely valuable in the human experience: to be able to empathize, imagine, or make decisions not based on logic alone but on compassion and understanding (Nussbaum, 2001).

The future of governance could not be about machines ruling humans or humans ruling machines but finding that middle-ground system in which human wisdom and machine intelligence work together. Machines, with their huge processing power and predictive capabilities, might lead human society to unprecedented efficiency and prosperity. It is the humans, though, in both their lived experience, ethical framing, and emotional intelligence, who provide the grounding through which governance can be just and compassionate, therefore meaningful (Wolfe, 2010).

**Governance in a Posthuman Condition**\
Entering the post-human era, we would face questions of not merely who should rule but also how we should rule; the eventual form this system of governance takes will likely be quite alien from what anyone has seen to date. The lines that separated the human and machine as ruler and ruled would blur and fade (Hayles, 1999).

It will need us to rethink not just our political systems but also our deeply philosophical assumptions regarding power, intelligence, and agency (Wiener, 1988). As Francis Fukuyama contemplatively predicted, the "end of history" may indeed coincide with the solving of the great technical problems of our age and pass beyond the ideological struggles of the past (Fukuyama, 2002). But perhaps this is not the end at all—perhaps, rather, it is the beginning of a new era, one in which governance is not about dominance or control but about collaboration, wisdom, and mutual flourishing of both humans and machines (Clark, 2003).

And in this future, who should rule? Perhaps the answer is no one—or rather, everybody. Perhaps governance itself will become a shared project, a collaborative activity in which human judgment and machine intelligence come together in such a way that the resulting system serves not one species alone but all conscious life forms, biological and artificial, within this wondrous and still quite mysterious universe (Clark, 2003).
